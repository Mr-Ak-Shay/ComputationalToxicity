{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install torch_geometric"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wcooPAiqeo9_",
        "outputId": "187f2b32-6af4-416f-8e72-f9646a8a6019"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torch_geometric\n",
            "  Downloading torch_geometric-2.6.1-py3-none-any.whl.metadata (63 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/63.1 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.1/63.1 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (3.11.13)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (2024.10.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (3.1.5)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (1.26.4)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (5.9.5)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (3.2.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (4.67.1)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (2.4.6)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (25.1.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (0.3.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (1.18.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch_geometric) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->torch_geometric) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->torch_geometric) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->torch_geometric) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->torch_geometric) (2025.1.31)\n",
            "Downloading torch_geometric-2.6.1-py3-none-any.whl (1.1 MB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.1 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m62.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: torch_geometric\n",
            "Successfully installed torch_geometric-2.6.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4ijKAEASaAxA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6404eba5-1764-49fe-9687-c98332d3308b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-9825d0fb1bf4>:8: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  data_list = torch.load(\"processed_graphs.pt\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded graphs: 679269\n",
            "Example Graph Object:\n",
            " Data(x=[25, 6], edge_index=[2, 54], edge_attr=[54, 4], y=[1], global_features=[1028])\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import zipfile\n",
        "import os\n",
        "\n",
        "with zipfile.ZipFile(\"processed_graphs.pt.zip\", \"r\") as zip_ref:\n",
        "    zip_ref.extractall(\".\")\n",
        "\n",
        "data_list = torch.load(\"processed_graphs.pt\")\n",
        "print(\"Loaded graphs:\", len(data_list))\n",
        "print(\"Example Graph Object:\\n\", data_list[0])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.nn import GATConv, global_add_pool\n",
        "\n",
        "class AttentionFusion(nn.Module):\n",
        "    def __init__(self, graph_dim, fingerprint_dim, fusion_dim):\n",
        "        super().__init__()\n",
        "        self.query_graph = nn.Linear(graph_dim, fusion_dim)\n",
        "        self.key_fp = nn.Linear(fingerprint_dim, fusion_dim)\n",
        "        self.value_fp = nn.Linear(fingerprint_dim, fusion_dim)\n",
        "\n",
        "    def forward(self, graph_repr, fingerprint):\n",
        "        Q = self.query_graph(graph_repr).unsqueeze(1)\n",
        "        K = self.key_fp(fingerprint).unsqueeze(1)\n",
        "        V = self.value_fp(fingerprint).unsqueeze(1)\n",
        "\n",
        "        attention_weights = torch.softmax(Q @ K.transpose(-2, -1) / (K.size(-1) ** 0.5), dim=-1)\n",
        "        attended_fp = (attention_weights @ V).squeeze(1)\n",
        "\n",
        "        return graph_repr + attended_fp\n",
        "\n",
        "class MolGraphormer(nn.Module):\n",
        "  def __init__(self, node_dim=6, edge_dim=4, hidden_dim=128, fingerprint_dim=1028, fusion_dim=128, output_dim=1):\n",
        "        super().__init__()\n",
        "        self.conv1 = GATConv(node_dim, hidden_dim, heads=4, concat=False, edge_dim=edge_dim)\n",
        "        self.conv2 = GATConv(hidden_dim, hidden_dim, heads=4, concat=False, edge_dim=edge_dim)\n",
        "        self.norm1 = nn.LayerNorm(hidden_dim)\n",
        "        self.norm2 = nn.LayerNorm(hidden_dim)\n",
        "        self.pool = global_add_pool\n",
        "        self.att_fusion = AttentionFusion(hidden_dim, fingerprint_dim, fusion_dim)\n",
        "\n",
        "        self.outlier_detector = nn.Sequential(\n",
        "            nn.Linear(hidden_dim, 64),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(64, 1),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "        self.output_head = nn.Sequential(\n",
        "            nn.Linear(hidden_dim, 64),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.2),\n",
        "            nn.Linear(64, output_dim)\n",
        "        )\n",
        "\n",
        "  def forward(self, data):\n",
        "    x, edge_index, edge_attr, batch = data.x, data.edge_index, data.edge_attr, data.batch\n",
        "\n",
        "    x = self.norm1(self.conv1(x, edge_index, edge_attr))\n",
        "    x = F.relu(x)\n",
        "    x = self.norm2(self.conv2(x, edge_index, edge_attr))\n",
        "    x = F.relu(x)\n",
        "\n",
        "    graph_repr = self.pool(x, batch)\n",
        "\n",
        "    batch_size = graph_repr.size(0)\n",
        "    if data.global_features.dim() == 2:\n",
        "        fingerprints = data.global_features\n",
        "    else:\n",
        "        fingerprints = data.global_features.view(batch_size, -1)\n",
        "\n",
        "    fused_repr = self.att_fusion(graph_repr, fingerprints)\n",
        "\n",
        "    outlier_score = self.outlier_detector(fused_repr)\n",
        "    output = self.output_head(fused_repr)\n",
        "\n",
        "    return output, outlier_score\n",
        "\n"
      ],
      "metadata": {
        "id": "7fLegVC5g-En"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch_geometric.data import Batch\n",
        "\n",
        "sample_batch = Batch.from_data_list(data_list[:32])\n",
        "model = MolGraphormer()\n",
        "output, outlier_score = model(sample_batch)\n",
        "print(\"Output:\", output.shape)\n",
        "print(\"Outlier Score:\", outlier_score.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sDml3ASfi6dA",
        "outputId": "408e22af-7602-427b-910b-c0874c4e3530"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Output: torch.Size([32, 1])\n",
            "Outlier Score: torch.Size([32, 1])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "task_loss_fn = nn.MSELoss()\n",
        "outlier_loss_fn = nn.BCELoss()\n",
        "\n",
        "def combined_loss_fn(task_output, target, outlier_score):\n",
        "    task_loss = task_loss_fn(task_output, target)\n",
        "    outlier_reg = torch.mean(outlier_score)\n",
        "    total_loss = task_loss + 0.1 * outlier_reg\n",
        "    return total_loss"
      ],
      "metadata": {
        "id": "4WiX0bA6jrLe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = MolGraphormer()\n",
        "optimizer = optim.AdamW(model.parameters(), lr=1e-4, weight_decay=1e-5)\n",
        "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.7)"
      ],
      "metadata": {
        "id": "4m7CI1SkjxU8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch_geometric.loader import DataLoader\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "train_data, temp_data = train_test_split(data_list, test_size=0.2, random_state=42)\n",
        "val_data, test_data = train_test_split(temp_data, test_size=0.5, random_state=42)\n",
        "\n",
        "train_loader = DataLoader(train_data, batch_size=32, shuffle=True)\n",
        "val_loader = DataLoader(val_data, batch_size=32)\n",
        "test_loader = DataLoader(test_data, batch_size=32)"
      ],
      "metadata": {
        "id": "AAYcrHyej2tO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import mean_absolute_error, r2_score, mean_squared_error\n",
        "import numpy as np\n",
        "\n",
        "def train_epoch(model, loader, optimizer, device):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    for batch in loader:\n",
        "        batch = batch.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        output, outlier_score = model(batch)\n",
        "        loss = combined_loss_fn(output, batch.y.view(-1, 1).float(), outlier_score)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item()\n",
        "    return total_loss / len(loader)\n",
        "\n",
        "def eval_epoch(model, loader, device):\n",
        "    model.eval()\n",
        "    y_true, y_pred = [], []\n",
        "    total_loss = 0\n",
        "    with torch.no_grad():\n",
        "        for batch in loader:\n",
        "            batch = batch.to(device)\n",
        "            output, outlier_score = model(batch)\n",
        "            loss = combined_loss_fn(output, batch.y.view(-1, 1).float(), outlier_score)\n",
        "            total_loss += loss.item()\n",
        "            y_true.extend(batch.y.view(-1).tolist())\n",
        "            y_pred.extend(output.view(-1).tolist())\n",
        "\n",
        "    mae = mean_absolute_error(y_true, y_pred)\n",
        "    rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
        "    r2 = r2_score(y_true, y_pred)\n",
        "    return total_loss / len(loader), mae, rmse, r2\n"
      ],
      "metadata": {
        "id": "lwYXHvFOj5xC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import torch\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model.to(device)\n",
        "\n",
        "epochs = 17\n",
        "patience = 3\n",
        "checkpoint_every = 3\n",
        "\n",
        "best_val_loss = float('inf')\n",
        "trigger_times = 0\n",
        "\n",
        "for epoch in range(1, epochs + 1):\n",
        "    start_time = time.time()\n",
        "\n",
        "    train_loss = train_epoch(model, train_loader, optimizer, device)\n",
        "    val_loss, val_mae, val_rmse, val_r2 = eval_epoch(model, val_loader, device)\n",
        "    scheduler.step()\n",
        "\n",
        "    print(f\"Epoch {epoch:02d} | Train Loss: {train_loss:.4f} | Val Loss: {val_loss:.4f} | MAE: {val_mae:.4f} | RMSE: {val_rmse:.4f} | R2: {val_r2:.4f} | Time: {time.time() - start_time:.2f}s\")\n",
        "    if epoch % checkpoint_every == 0:\n",
        "        torch.save(model.state_dict(), f\"molgraphormer_epoch_{epoch}.pt\")\n",
        "\n",
        "    if val_loss < best_val_loss:\n",
        "        best_val_loss = val_loss\n",
        "        trigger_times = 0\n",
        "        torch.save(model.state_dict(), \"best_molgraphormer.pt\")\n",
        "        print(\"Saved new best model\")\n",
        "    else:\n",
        "        trigger_times += 1\n",
        "        print(f\"No improvement for {trigger_times} epochs\")\n",
        "\n",
        "    if trigger_times >= patience:\n",
        "        print(f\"\\n Early stopping at epoch {epoch} (patience: {patience})\")\n",
        "        break\n"
      ],
      "metadata": {
        "id": "-qYpEDRs8TQn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch_geometric.loader import DataLoader\n",
        "import torch\n",
        "\n",
        "torch.manual_seed(42)\n",
        "\n",
        "num_samples = len(data_list)\n",
        "train_ratio, val_ratio, test_ratio = 0.8, 0.1, 0.1\n",
        "\n",
        "train_size = int(train_ratio * num_samples)\n",
        "val_size = int(val_ratio * num_samples)\n",
        "test_size = num_samples - train_size - val_size\n",
        "\n",
        "train_graphs = data_list[:train_size]\n",
        "val_graphs = data_list[train_size:train_size + val_size]\n",
        "test_graphs = data_list[train_size + val_size:]\n",
        "\n",
        "train_loader = DataLoader(train_graphs, batch_size=32, shuffle=True)\n",
        "val_loader = DataLoader(val_graphs, batch_size=32, shuffle=False)\n",
        "test_loader = DataLoader(test_graphs, batch_size=32, shuffle=False)\n",
        "\n",
        "print(f\"Train samples: {len(train_graphs)}\")\n",
        "print(f\"Validation samples: {len(val_graphs)}\")\n",
        "print(f\"Test samples: {len(test_graphs)}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FAYMvWti0Jn1",
        "outputId": "73c303af-d84e-44ab-b7e0-a005c9d731a4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train samples: 543415\n",
            "Validation samples: 67926\n",
            "Test samples: 67928\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "node_dim = 6\n",
        "edge_dim = 4\n",
        "hidden_dim = 128\n",
        "fingerprint_dim = 1028\n",
        "fusion_dim = 128\n",
        "output_dim = 1\n",
        "\n",
        "model = MolGraphormer(node_dim=node_dim, edge_dim=edge_dim, hidden_dim=hidden_dim,\n",
        "                      fingerprint_dim=fingerprint_dim, fusion_dim=fusion_dim, output_dim=output_dim)\n",
        "\n",
        "model.load_state_dict(torch.load(\"best_molgraphormer.pt\", map_location=device))\n",
        "model.to(device)\n",
        "\n",
        "model.eval()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AByCSq7a3YLE",
        "outputId": "134579e4-0c04-4c0a-887e-fe43da8dbfe6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-12-3590ba13bf7d>:13: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  model.load_state_dict(torch.load(\"best_molgraphormer.pt\", map_location=device))\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MolGraphormer(\n",
              "  (conv1): GATConv(6, 128, heads=4)\n",
              "  (conv2): GATConv(128, 128, heads=4)\n",
              "  (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
              "  (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
              "  (att_fusion): AttentionFusion(\n",
              "    (query_graph): Linear(in_features=128, out_features=128, bias=True)\n",
              "    (key_fp): Linear(in_features=1028, out_features=128, bias=True)\n",
              "    (value_fp): Linear(in_features=1028, out_features=128, bias=True)\n",
              "  )\n",
              "  (outlier_detector): Sequential(\n",
              "    (0): Linear(in_features=128, out_features=64, bias=True)\n",
              "    (1): ReLU()\n",
              "    (2): Linear(in_features=64, out_features=1, bias=True)\n",
              "    (3): Sigmoid()\n",
              "  )\n",
              "  (output_head): Sequential(\n",
              "    (0): Linear(in_features=128, out_features=64, bias=True)\n",
              "    (1): ReLU()\n",
              "    (2): Dropout(p=0.2, inplace=False)\n",
              "    (3): Linear(in_features=64, out_features=1, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import mean_absolute_error, r2_score\n",
        "import numpy as np\n",
        "\n",
        "def evaluate_model(model, loader, device):\n",
        "    model.eval()\n",
        "    all_preds, all_labels = [], []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in loader:\n",
        "            batch = batch.to(device)\n",
        "            output, _ = model(batch)\n",
        "            all_preds.append(output.cpu().numpy())\n",
        "            all_labels.append(batch.y.cpu().numpy())\n",
        "\n",
        "    y_true = np.concatenate(all_labels)\n",
        "    y_pred = np.concatenate(all_preds)\n",
        "\n",
        "    rmse = np.sqrt(np.mean((y_true - y_pred) ** 2))\n",
        "\n",
        "    mae = mean_absolute_error(y_true, y_pred)\n",
        "    r2 = r2_score(y_true, y_pred)\n",
        "\n",
        "    print(f\"Test Set RMSE: {rmse:.4f}\")\n",
        "    print(f\"Test Set MAE: {mae:.4f}\")\n",
        "    print(f\"Test Set R² Score: {r2:.4f}\")\n",
        "\n",
        "    return y_true, y_pred\n"
      ],
      "metadata": {
        "id": "NOqKimpB21UU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U scikit-learn"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DqUz-2SD5U8u",
        "outputId": "1cec63aa-9723-4653-f9cf-8e9e154c395f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.1)\n",
            "Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.26.4)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.13.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.5.0)\n"
          ]
        }
      ]
    }
  ]
}